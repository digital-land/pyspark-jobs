# Production dependencies for PySpark Jobs

# Core PySpark framework
pyspark>=3.3.0,<4.0.0

# AWS SDK and services
boto3>=1.26.0
botocore>=1.29.0

# Database connectivity
psycopg2-binary>=2.9.0

# Configuration and data handling
PyYAML>=6.0

# Python standard library extensions (if needed)
# Note: Most imports (json, os, logging, argparse, etc.) are part of Python standard library

# Optional: Data validation and typing
typing-extensions>=4.0.0

# Package metadata
setuptools>=65.0.0
