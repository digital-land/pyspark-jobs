{
    "project": "pyspark-jobs",
    "version": "0.1.0",
    "build_timestamp": "2025-08-12T23:11:06Z",
    "s3_bucket": "development-pyspark-jobs-codepackage",
    "files": {
        "wheel_package": {
            "local_path": "whl_pkg/pyspark_jobs-0.1.0-py3-none-any.whl",
            "s3_path": "s3://development-pyspark-jobs-codepackage/pkg/whl_pkg/pyspark_jobs-0.1.0-py3-none-any.whl",
            "description": "Main application wheel package"
        },
        "dependencies": {
            "local_path": "dependencies/dependencies.tar.gz",
            "s3_path": "s3://development-pyspark-jobs-codepackage/pkg/dependencies/dependencies.tar.gz",
            "description": "External Python dependencies archive"
        },
        "entry_script": {
            "local_path": "entry_script/run_main.py",
            "s3_path": "s3://development-pyspark-jobs-codepackage/pkg/entry_script/run_main.py",
            "description": "Job entry point script"
        }
    },
    "emr_serverless_config": {
        "entryPoint": "s3://development-pyspark-jobs-codepackage/pkg/entry_script/run_main.py",
        "sparkSubmitParameters": "--py-files s3://development-pyspark-jobs-codepackage/pkg/whl_pkg/pyspark_jobs-0.1.0-py3-none-any.whl --archives s3://development-pyspark-jobs-codepackage/pkg/dependencies/dependencies.tar.gz#deps --conf spark.emr-serverless.driverEnv.PYTHONPATH=/home/hadoop/deps --conf spark.emr-serverless.executorEnv.PYTHONPATH=/home/hadoop/deps"
    }
}
