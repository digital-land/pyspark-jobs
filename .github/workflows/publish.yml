name: Publish 
run-name: Publish - ${{ github.head_ref || github.ref_name }} to ${{ inputs.environment }} by @${{ github.actor }}

on:
  push:
    branches-ignore: [main]
  workflow_dispatch:
    inputs:
      environment:
        type: environment
        description: The environment to deploy to.

jobs:
  test:
    uses: ./.github/workflows/test.yml
    secrets: inherit

  detect-environments:
    runs-on: ubuntu-latest
    outputs:
      environments: ${{ steps.environments.outputs.result }}
    steps:
      - uses: actions/github-script@v6
        id: environments
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          result-encoding: json
          script: |
            const allowed = ['development', 'staging', 'production'];
            // If triggered manually with an environment in the allowed array, return it
            if (context.payload?.inputs?.environment) {
              const env = context.payload.inputs.environment
              return allowed.includes(env) ? [env] : [];
            }

            // fetch all repo environments
            const { data: { environments } } = await github.rest.repos.getAllEnvironments({
              owner: context.repo.owner,
              repo: context.repo.repo
            });

            // Otherwise fetch all defined GitHub Environments
            return environments.map(e => e.name).filter(name => allowed.includes(name));

  build:
    runs-on: ubuntu-latest
    # needs: [test]
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Build artifacts
        run: |
          bash build_aws_package.sh

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pyspark-build-artifacts
          path: build_output/
          retention-days: 7

  publish:
    runs-on: ubuntu-latest
    needs: [build, detect-environments]
    strategy:
      matrix:
        environment: ${{ fromJSON(needs.detect-environments.outputs.environments) }}
    environment: ${{ matrix.environment }}
    env:
      AWS_S3_BUCKET: ${{ secrets.DEPLOY_PYSPARK_JOBS_CODEPACKAGE_BUCKET }}
      ENVIRONMENT: ${{ matrix.environment }}
    steps:
      - uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: pyspark-build-artifacts
          path: build_output/

      - name: Install AWS CLI
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip -q awscliv2.zip
          sudo ./aws/install --update

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.DEPLOY_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.DEPLOY_AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-west-2

      - name: Publish to S3
        run: |
          echo "üöÄ Publishing PySpark jobs to $ENVIRONMENT environment..."
          aws s3 cp build_output/whl_pkg/ s3://$AWS_S3_BUCKET/pkg/whl_pkg/ --recursive
          aws s3 cp build_output/dependencies/dependencies.zip s3://$AWS_S3_BUCKET/pkg/dependencies/
          aws s3 cp build_output/entry_script/run_main.py s3://$AWS_S3_BUCKET/pkg/entry_script/
          aws s3 cp build_output/jars/ s3://$AWS_S3_BUCKET/pkg/jars/ --recursive
          echo "‚úÖ Publish completed to S3 bucket: $AWS_S3_BUCKET"

      - name: Verify Publishment
        run: |
          echo "üîç Verifying published artifacts..."
          aws s3 ls s3://$AWS_S3_BUCKET/pkg/whl_pkg/ --recursive
          aws s3 ls s3://$AWS_S3_BUCKET/pkg/dependencies/
          aws s3 ls s3://$AWS_S3_BUCKET/pkg/entry_script/
          echo "‚úÖ All artifacts successfully published to S3 bucket: $AWS_S3_BUCKET"
