name: Publish 
run-name: Publish - ${{ github.head_ref || github.ref_name }} to ${{ inputs.environment }} by @${{ github.actor }}

on:
  push:
    branches-ignore: [main]
  workflow_dispatch:
    inputs:
      environment:
        type: environment
        description: The environment to deploy to.

jobs:
  detect-environments:
    runs-on: ubuntu-latest
    outputs:
      environments: ${{ steps.environments.outputs.result }}
    steps:
      - uses: actions/github-script@v6
        id: environments
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          result-encoding: json
          script: |
            if (context.payload?.inputs?.environment) return [context.payload?.inputs?.environment];
            const {data: {environments}} =
              await github.request(`GET /repos/${process.env.GITHUB_REPOSITORY}/environments`);
            return environments.map(e => e.name)

  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install --upgrade pip setuptools wheel
          pip install -r requirements-local.txt

      - name: Run tests
        run: |
          pytest tests/unit -v

  build:
    runs-on: ubuntu-latest
    needs: [test]
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Build artifacts
        run: |
          bash build_aws_package.sh

      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: pyspark-build-artifacts
          path: build_output/
          retention-days: 7

  publish:
    runs-on: ubuntu-latest
    needs: [build, detect-environments]
    strategy:
      matrix:
        environment: ${{ fromJSON(needs.detect-environments.outputs.environments) }}
    environment: ${{ matrix.environment }}
    env:
      AWS_S3_BUCKET: ${{ secrets.PYSPARK_JOBS_S3_BUCKET }}
      ENVIRONMENT: ${{ matrix.environment }}
    steps:
      - uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v3
        with:
          name: pyspark-build-artifacts
          path: build_output/

      - name: Install AWS CLI
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip -q awscliv2.zip
          sudo ./aws/install --update

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.DEPLOY_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.DEPLOY_AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-west-2

      - name: Publish to S3
        run: |
          aws s3 cp build_output/whl_pkg/ s3://$AWS_S3_BUCKET/pkg/whl_pkg/ --recursive
          aws s3 cp build_output/dependencies/dependencies.zip s3://$AWS_S3_BUCKET/pkg/dependencies/
          aws s3 cp build_output/entry_script/run_main.py s3://$AWS_S3_BUCKET/pkg/entry_script/
          aws s3 cp build_output/jars/ s3://$AWS_S3_BUCKET/pkg/jars/ --recursive
